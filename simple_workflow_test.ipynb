{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4439101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2d\n",
    "import importlib\n",
    "importlib.reload(d2d)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5163b890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['DAS Data', 'Discharge', 'Times']>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2487</th>\n",
       "      <th>2488</th>\n",
       "      <th>2489</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>Discharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055370</td>\n",
       "      <td>0.132891</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.092913</td>\n",
       "      <td>0.067835</td>\n",
       "      <td>0.123561</td>\n",
       "      <td>0.831771</td>\n",
       "      <td>0.081936</td>\n",
       "      <td>0.333693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797420</td>\n",
       "      <td>0.186061</td>\n",
       "      <td>0.245533</td>\n",
       "      <td>0.112796</td>\n",
       "      <td>0.951247</td>\n",
       "      <td>-0.005196</td>\n",
       "      <td>0.075232</td>\n",
       "      <td>0.105298</td>\n",
       "      <td>4160.545583</td>\n",
       "      <td>-0.199862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.609165</td>\n",
       "      <td>2.642731</td>\n",
       "      <td>2.592007</td>\n",
       "      <td>-0.425048</td>\n",
       "      <td>-0.448878</td>\n",
       "      <td>-0.351154</td>\n",
       "      <td>-0.345852</td>\n",
       "      <td>-0.572293</td>\n",
       "      <td>-0.602395</td>\n",
       "      <td>-0.588788</td>\n",
       "      <td>...</td>\n",
       "      <td>2.639816</td>\n",
       "      <td>2.626478</td>\n",
       "      <td>2.622412</td>\n",
       "      <td>2.635967</td>\n",
       "      <td>2.628929</td>\n",
       "      <td>2.636206</td>\n",
       "      <td>2.631859</td>\n",
       "      <td>2.628562</td>\n",
       "      <td>8178.032001</td>\n",
       "      <td>-0.203829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.641601</td>\n",
       "      <td>2.626772</td>\n",
       "      <td>2.582383</td>\n",
       "      <td>-0.432204</td>\n",
       "      <td>-0.455639</td>\n",
       "      <td>-0.353222</td>\n",
       "      <td>-0.353055</td>\n",
       "      <td>-0.574172</td>\n",
       "      <td>-0.602123</td>\n",
       "      <td>-0.589121</td>\n",
       "      <td>...</td>\n",
       "      <td>2.618368</td>\n",
       "      <td>2.633073</td>\n",
       "      <td>2.625496</td>\n",
       "      <td>2.622513</td>\n",
       "      <td>2.623606</td>\n",
       "      <td>2.620045</td>\n",
       "      <td>2.620419</td>\n",
       "      <td>2.634475</td>\n",
       "      <td>8163.918322</td>\n",
       "      <td>-0.205529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.608541</td>\n",
       "      <td>2.623200</td>\n",
       "      <td>2.590291</td>\n",
       "      <td>-0.440592</td>\n",
       "      <td>-0.460897</td>\n",
       "      <td>-0.360812</td>\n",
       "      <td>-0.356249</td>\n",
       "      <td>-0.572446</td>\n",
       "      <td>-0.602283</td>\n",
       "      <td>-0.590442</td>\n",
       "      <td>...</td>\n",
       "      <td>2.614139</td>\n",
       "      <td>2.607113</td>\n",
       "      <td>2.605096</td>\n",
       "      <td>2.638779</td>\n",
       "      <td>2.602809</td>\n",
       "      <td>2.621506</td>\n",
       "      <td>2.612316</td>\n",
       "      <td>2.596673</td>\n",
       "      <td>8161.652382</td>\n",
       "      <td>-0.207229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.623933</td>\n",
       "      <td>2.609213</td>\n",
       "      <td>2.592907</td>\n",
       "      <td>-0.427993</td>\n",
       "      <td>-0.458665</td>\n",
       "      <td>-0.361094</td>\n",
       "      <td>-0.358925</td>\n",
       "      <td>-0.571576</td>\n",
       "      <td>-0.601865</td>\n",
       "      <td>-0.591103</td>\n",
       "      <td>...</td>\n",
       "      <td>2.624064</td>\n",
       "      <td>2.638370</td>\n",
       "      <td>2.632476</td>\n",
       "      <td>2.601060</td>\n",
       "      <td>2.621953</td>\n",
       "      <td>2.607497</td>\n",
       "      <td>2.641087</td>\n",
       "      <td>2.636136</td>\n",
       "      <td>8234.212679</td>\n",
       "      <td>-0.208929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62740</th>\n",
       "      <td>2.644459</td>\n",
       "      <td>2.640414</td>\n",
       "      <td>2.592968</td>\n",
       "      <td>-0.353144</td>\n",
       "      <td>-0.426673</td>\n",
       "      <td>-0.302467</td>\n",
       "      <td>-0.440626</td>\n",
       "      <td>-0.605681</td>\n",
       "      <td>-0.595740</td>\n",
       "      <td>-0.598741</td>\n",
       "      <td>...</td>\n",
       "      <td>2.639635</td>\n",
       "      <td>2.641696</td>\n",
       "      <td>2.649847</td>\n",
       "      <td>2.639092</td>\n",
       "      <td>2.654711</td>\n",
       "      <td>2.607855</td>\n",
       "      <td>2.646024</td>\n",
       "      <td>2.648450</td>\n",
       "      <td>8189.577468</td>\n",
       "      <td>-0.416159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62741</th>\n",
       "      <td>2.666290</td>\n",
       "      <td>2.630778</td>\n",
       "      <td>2.594296</td>\n",
       "      <td>-0.351444</td>\n",
       "      <td>-0.427582</td>\n",
       "      <td>-0.286583</td>\n",
       "      <td>-0.434774</td>\n",
       "      <td>-0.606149</td>\n",
       "      <td>-0.596309</td>\n",
       "      <td>-0.597133</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642260</td>\n",
       "      <td>2.632740</td>\n",
       "      <td>2.637970</td>\n",
       "      <td>2.625693</td>\n",
       "      <td>2.653305</td>\n",
       "      <td>2.628002</td>\n",
       "      <td>2.618845</td>\n",
       "      <td>2.624307</td>\n",
       "      <td>8194.036074</td>\n",
       "      <td>-0.416357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62742</th>\n",
       "      <td>2.637746</td>\n",
       "      <td>2.629654</td>\n",
       "      <td>2.595306</td>\n",
       "      <td>-0.352068</td>\n",
       "      <td>-0.428374</td>\n",
       "      <td>-0.280593</td>\n",
       "      <td>-0.438196</td>\n",
       "      <td>-0.606441</td>\n",
       "      <td>-0.596674</td>\n",
       "      <td>-0.595969</td>\n",
       "      <td>...</td>\n",
       "      <td>2.662767</td>\n",
       "      <td>2.637987</td>\n",
       "      <td>2.630461</td>\n",
       "      <td>2.613858</td>\n",
       "      <td>2.636926</td>\n",
       "      <td>2.617872</td>\n",
       "      <td>2.613045</td>\n",
       "      <td>2.623067</td>\n",
       "      <td>8220.779280</td>\n",
       "      <td>-0.416555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62743</th>\n",
       "      <td>2.636491</td>\n",
       "      <td>2.639474</td>\n",
       "      <td>2.620006</td>\n",
       "      <td>-0.354822</td>\n",
       "      <td>-0.427148</td>\n",
       "      <td>-0.275793</td>\n",
       "      <td>-0.433923</td>\n",
       "      <td>-0.606532</td>\n",
       "      <td>-0.596980</td>\n",
       "      <td>-0.595063</td>\n",
       "      <td>...</td>\n",
       "      <td>2.637306</td>\n",
       "      <td>2.630241</td>\n",
       "      <td>2.654636</td>\n",
       "      <td>2.651023</td>\n",
       "      <td>2.606471</td>\n",
       "      <td>2.627836</td>\n",
       "      <td>2.644935</td>\n",
       "      <td>2.651291</td>\n",
       "      <td>8207.721162</td>\n",
       "      <td>-0.416753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62744</th>\n",
       "      <td>2.640121</td>\n",
       "      <td>2.640211</td>\n",
       "      <td>2.623241</td>\n",
       "      <td>-0.353725</td>\n",
       "      <td>-0.429409</td>\n",
       "      <td>-0.094617</td>\n",
       "      <td>-0.347895</td>\n",
       "      <td>-0.604096</td>\n",
       "      <td>-0.595106</td>\n",
       "      <td>-0.592213</td>\n",
       "      <td>...</td>\n",
       "      <td>2.648930</td>\n",
       "      <td>2.648782</td>\n",
       "      <td>2.665711</td>\n",
       "      <td>2.635439</td>\n",
       "      <td>2.636522</td>\n",
       "      <td>2.638580</td>\n",
       "      <td>2.630080</td>\n",
       "      <td>2.662356</td>\n",
       "      <td>8184.079806</td>\n",
       "      <td>-0.416951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62745 rows Ã— 2497 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.055370  0.132891  0.075625  0.838384  0.092913  0.067835  0.123561   \n",
       "1      2.609165  2.642731  2.592007 -0.425048 -0.448878 -0.351154 -0.345852   \n",
       "2      2.641601  2.626772  2.582383 -0.432204 -0.455639 -0.353222 -0.353055   \n",
       "3      2.608541  2.623200  2.590291 -0.440592 -0.460897 -0.360812 -0.356249   \n",
       "4      2.623933  2.609213  2.592907 -0.427993 -0.458665 -0.361094 -0.358925   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "62740  2.644459  2.640414  2.592968 -0.353144 -0.426673 -0.302467 -0.440626   \n",
       "62741  2.666290  2.630778  2.594296 -0.351444 -0.427582 -0.286583 -0.434774   \n",
       "62742  2.637746  2.629654  2.595306 -0.352068 -0.428374 -0.280593 -0.438196   \n",
       "62743  2.636491  2.639474  2.620006 -0.354822 -0.427148 -0.275793 -0.433923   \n",
       "62744  2.640121  2.640211  2.623241 -0.353725 -0.429409 -0.094617 -0.347895   \n",
       "\n",
       "              7         8         9  ...      2487      2488      2489  \\\n",
       "0      0.831771  0.081936  0.333693  ...  0.797420  0.186061  0.245533   \n",
       "1     -0.572293 -0.602395 -0.588788  ...  2.639816  2.626478  2.622412   \n",
       "2     -0.574172 -0.602123 -0.589121  ...  2.618368  2.633073  2.625496   \n",
       "3     -0.572446 -0.602283 -0.590442  ...  2.614139  2.607113  2.605096   \n",
       "4     -0.571576 -0.601865 -0.591103  ...  2.624064  2.638370  2.632476   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "62740 -0.605681 -0.595740 -0.598741  ...  2.639635  2.641696  2.649847   \n",
       "62741 -0.606149 -0.596309 -0.597133  ...  2.642260  2.632740  2.637970   \n",
       "62742 -0.606441 -0.596674 -0.595969  ...  2.662767  2.637987  2.630461   \n",
       "62743 -0.606532 -0.596980 -0.595063  ...  2.637306  2.630241  2.654636   \n",
       "62744 -0.604096 -0.595106 -0.592213  ...  2.648930  2.648782  2.665711   \n",
       "\n",
       "           2490      2491      2492      2493      2494         2495  \\\n",
       "0      0.112796  0.951247 -0.005196  0.075232  0.105298  4160.545583   \n",
       "1      2.635967  2.628929  2.636206  2.631859  2.628562  8178.032001   \n",
       "2      2.622513  2.623606  2.620045  2.620419  2.634475  8163.918322   \n",
       "3      2.638779  2.602809  2.621506  2.612316  2.596673  8161.652382   \n",
       "4      2.601060  2.621953  2.607497  2.641087  2.636136  8234.212679   \n",
       "...         ...       ...       ...       ...       ...          ...   \n",
       "62740  2.639092  2.654711  2.607855  2.646024  2.648450  8189.577468   \n",
       "62741  2.625693  2.653305  2.628002  2.618845  2.624307  8194.036074   \n",
       "62742  2.613858  2.636926  2.617872  2.613045  2.623067  8220.779280   \n",
       "62743  2.651023  2.606471  2.627836  2.644935  2.651291  8207.721162   \n",
       "62744  2.635439  2.636522  2.638580  2.630080  2.662356  8184.079806   \n",
       "\n",
       "       Discharge  \n",
       "0      -0.199862  \n",
       "1      -0.203829  \n",
       "2      -0.205529  \n",
       "3      -0.207229  \n",
       "4      -0.208929  \n",
       "...          ...  \n",
       "62740  -0.416159  \n",
       "62741  -0.416357  \n",
       "62742  -0.416555  \n",
       "62743  -0.416753  \n",
       "62744  -0.416951  \n",
       "\n",
       "[62745 rows x 2497 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear, lstm_model, dnn_model, df_all_chan,input_columns  = d2d.import_data()\n",
    "\n",
    "da = df_all_chan.to_numpy()\n",
    "\n",
    "chan_mean = da[:,0:2495].flatten().mean()\n",
    "chan_std = da[:,0:2495].flatten().std()\n",
    "discharge_mean = da[:,2496].flatten().mean()\n",
    "discharge_std = da[:,2496].flatten().std()\n",
    "\n",
    "da[:,0:2495] = (da[:,0:2495] - chan_mean) / chan_std\n",
    "da[:,2496] = (da[:,2496] - discharge_mean) / discharge_std\n",
    "df_all_chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0863cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_frame = pd.DataFrame({'0':range(0,10000), 'Discharge':range(0,10000)})\n",
    "input_columns = ['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ed31af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DAS observations: 62745\n",
      "Number of tf Dataset windows: 313\n"
     ]
    }
   ],
   "source": [
    "print('Number of DAS observations: %d'%df_all_chan.shape[0])\n",
    "window_input_width = 200\n",
    "print('Number of tf Dataset windows: %d'%np.floor(df_all_chan.shape[0]/window_input_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c92b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_window = d2d.WindowGenerator(test_data_frame,\n",
    "    input_width=window_input_width, label_width=1, shift=0,\n",
    "    label_columns=['Discharge'],\n",
    "    input_columns=input_columns,\n",
    "    shuffle=False)\n",
    "\n",
    "multi_step_window_shuffled = d2d.WindowGenerator(test_data_frame,\n",
    "    input_width=window_input_width, label_width=1, shift=0,\n",
    "    label_columns=['Discharge'],\n",
    "    input_columns=input_columns,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "775e68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test ds: 16\n",
      "Size of val ds: 15\n",
      "Size of train ds: 123\n",
      "Sum of ds sizes = 154\n"
     ]
    }
   ],
   "source": [
    "ntest = tf.data.experimental.cardinality(multi_step_window.test)\n",
    "nval = multi_step_window.val.cardinality().numpy()\n",
    "ntrain = multi_step_window.train.cardinality().numpy()\n",
    "print('Size of test ds: %d'%ntest)\n",
    "print('Size of val ds: %d'%nval)\n",
    "print('Size of train ds: %d'%ntrain)\n",
    "print('Sum of ds sizes = %d'%(ntest+nval+ntrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba3f1db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 200, 1), dtype=float32, numpy=\n",
       " array([[[  0.],\n",
       "         [  1.],\n",
       "         [  2.],\n",
       "         ...,\n",
       "         [197.],\n",
       "         [198.],\n",
       "         [199.]],\n",
       " \n",
       "        [[  1.],\n",
       "         [  2.],\n",
       "         [  3.],\n",
       "         ...,\n",
       "         [198.],\n",
       "         [199.],\n",
       "         [200.]],\n",
       " \n",
       "        [[  2.],\n",
       "         [  3.],\n",
       "         [  4.],\n",
       "         ...,\n",
       "         [199.],\n",
       "         [200.],\n",
       "         [201.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61.],\n",
       "         [ 62.],\n",
       "         [ 63.],\n",
       "         ...,\n",
       "         [258.],\n",
       "         [259.],\n",
       "         [260.]],\n",
       " \n",
       "        [[ 62.],\n",
       "         [ 63.],\n",
       "         [ 64.],\n",
       "         ...,\n",
       "         [259.],\n",
       "         [260.],\n",
       "         [261.]],\n",
       " \n",
       "        [[ 63.],\n",
       "         [ 64.],\n",
       "         [ 65.],\n",
       "         ...,\n",
       "         [260.],\n",
       "         [261.],\n",
       "         [262.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 1), dtype=float32, numpy=\n",
       " array([[[199.]],\n",
       " \n",
       "        [[200.]],\n",
       " \n",
       "        [[201.]],\n",
       " \n",
       "        [[202.]],\n",
       " \n",
       "        [[203.]],\n",
       " \n",
       "        [[204.]],\n",
       " \n",
       "        [[205.]],\n",
       " \n",
       "        [[206.]],\n",
       " \n",
       "        [[207.]],\n",
       " \n",
       "        [[208.]],\n",
       " \n",
       "        [[209.]],\n",
       " \n",
       "        [[210.]],\n",
       " \n",
       "        [[211.]],\n",
       " \n",
       "        [[212.]],\n",
       " \n",
       "        [[213.]],\n",
       " \n",
       "        [[214.]],\n",
       " \n",
       "        [[215.]],\n",
       " \n",
       "        [[216.]],\n",
       " \n",
       "        [[217.]],\n",
       " \n",
       "        [[218.]],\n",
       " \n",
       "        [[219.]],\n",
       " \n",
       "        [[220.]],\n",
       " \n",
       "        [[221.]],\n",
       " \n",
       "        [[222.]],\n",
       " \n",
       "        [[223.]],\n",
       " \n",
       "        [[224.]],\n",
       " \n",
       "        [[225.]],\n",
       " \n",
       "        [[226.]],\n",
       " \n",
       "        [[227.]],\n",
       " \n",
       "        [[228.]],\n",
       " \n",
       "        [[229.]],\n",
       " \n",
       "        [[230.]],\n",
       " \n",
       "        [[231.]],\n",
       " \n",
       "        [[232.]],\n",
       " \n",
       "        [[233.]],\n",
       " \n",
       "        [[234.]],\n",
       " \n",
       "        [[235.]],\n",
       " \n",
       "        [[236.]],\n",
       " \n",
       "        [[237.]],\n",
       " \n",
       "        [[238.]],\n",
       " \n",
       "        [[239.]],\n",
       " \n",
       "        [[240.]],\n",
       " \n",
       "        [[241.]],\n",
       " \n",
       "        [[242.]],\n",
       " \n",
       "        [[243.]],\n",
       " \n",
       "        [[244.]],\n",
       " \n",
       "        [[245.]],\n",
       " \n",
       "        [[246.]],\n",
       " \n",
       "        [[247.]],\n",
       " \n",
       "        [[248.]],\n",
       " \n",
       "        [[249.]],\n",
       " \n",
       "        [[250.]],\n",
       " \n",
       "        [[251.]],\n",
       " \n",
       "        [[252.]],\n",
       " \n",
       "        [[253.]],\n",
       " \n",
       "        [[254.]],\n",
       " \n",
       "        [[255.]],\n",
       " \n",
       "        [[256.]],\n",
       " \n",
       "        [[257.]],\n",
       " \n",
       "        [[258.]],\n",
       " \n",
       "        [[259.]],\n",
       " \n",
       "        [[260.]],\n",
       " \n",
       "        [[261.]],\n",
       " \n",
       "        [[262.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_step_window.example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83cded74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 200, 1), dtype=float32, numpy=\n",
       " array([[[5533.],\n",
       "         [5534.],\n",
       "         [5535.],\n",
       "         ...,\n",
       "         [5730.],\n",
       "         [5731.],\n",
       "         [5732.]],\n",
       " \n",
       "        [[7509.],\n",
       "         [7510.],\n",
       "         [7511.],\n",
       "         ...,\n",
       "         [7706.],\n",
       "         [7707.],\n",
       "         [7708.]],\n",
       " \n",
       "        [[6808.],\n",
       "         [6809.],\n",
       "         [6810.],\n",
       "         ...,\n",
       "         [7005.],\n",
       "         [7006.],\n",
       "         [7007.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[8099.],\n",
       "         [8100.],\n",
       "         [8101.],\n",
       "         ...,\n",
       "         [8296.],\n",
       "         [8297.],\n",
       "         [8298.]],\n",
       " \n",
       "        [[2213.],\n",
       "         [2214.],\n",
       "         [2215.],\n",
       "         ...,\n",
       "         [2410.],\n",
       "         [2411.],\n",
       "         [2412.]],\n",
       " \n",
       "        [[1667.],\n",
       "         [1668.],\n",
       "         [1669.],\n",
       "         ...,\n",
       "         [1864.],\n",
       "         [1865.],\n",
       "         [1866.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 1), dtype=float32, numpy=\n",
       " array([[[5732.]],\n",
       " \n",
       "        [[7708.]],\n",
       " \n",
       "        [[7007.]],\n",
       " \n",
       "        [[8143.]],\n",
       " \n",
       "        [[2587.]],\n",
       " \n",
       "        [[4635.]],\n",
       " \n",
       "        [[ 572.]],\n",
       " \n",
       "        [[4823.]],\n",
       " \n",
       "        [[7581.]],\n",
       " \n",
       "        [[5896.]],\n",
       " \n",
       "        [[7088.]],\n",
       " \n",
       "        [[9683.]],\n",
       " \n",
       "        [[6169.]],\n",
       " \n",
       "        [[2444.]],\n",
       " \n",
       "        [[3545.]],\n",
       " \n",
       "        [[7215.]],\n",
       " \n",
       "        [[5192.]],\n",
       " \n",
       "        [[9305.]],\n",
       " \n",
       "        [[6165.]],\n",
       " \n",
       "        [[8308.]],\n",
       " \n",
       "        [[6016.]],\n",
       " \n",
       "        [[4558.]],\n",
       " \n",
       "        [[1321.]],\n",
       " \n",
       "        [[1849.]],\n",
       " \n",
       "        [[7016.]],\n",
       " \n",
       "        [[4668.]],\n",
       " \n",
       "        [[9631.]],\n",
       " \n",
       "        [[8499.]],\n",
       " \n",
       "        [[7272.]],\n",
       " \n",
       "        [[6197.]],\n",
       " \n",
       "        [[5967.]],\n",
       " \n",
       "        [[ 820.]],\n",
       " \n",
       "        [[8769.]],\n",
       " \n",
       "        [[3645.]],\n",
       " \n",
       "        [[1952.]],\n",
       " \n",
       "        [[4218.]],\n",
       " \n",
       "        [[6660.]],\n",
       " \n",
       "        [[ 884.]],\n",
       " \n",
       "        [[3371.]],\n",
       " \n",
       "        [[9984.]],\n",
       " \n",
       "        [[7440.]],\n",
       " \n",
       "        [[ 286.]],\n",
       " \n",
       "        [[4509.]],\n",
       " \n",
       "        [[5067.]],\n",
       " \n",
       "        [[ 993.]],\n",
       " \n",
       "        [[3864.]],\n",
       " \n",
       "        [[8891.]],\n",
       " \n",
       "        [[8724.]],\n",
       " \n",
       "        [[3087.]],\n",
       " \n",
       "        [[1697.]],\n",
       " \n",
       "        [[6920.]],\n",
       " \n",
       "        [[6685.]],\n",
       " \n",
       "        [[3433.]],\n",
       " \n",
       "        [[ 356.]],\n",
       " \n",
       "        [[6328.]],\n",
       " \n",
       "        [[2505.]],\n",
       " \n",
       "        [[7740.]],\n",
       " \n",
       "        [[1677.]],\n",
       " \n",
       "        [[1653.]],\n",
       " \n",
       "        [[5050.]],\n",
       " \n",
       "        [[5222.]],\n",
       " \n",
       "        [[8298.]],\n",
       " \n",
       "        [[2412.]],\n",
       " \n",
       "        [[1866.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_step_window_shuffled.example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = d2d.compile_and_fit(linear, multi_step_window, learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = this_model.evaluate(multi_step_window.val)\n",
    "performance = this_model.evaluate(multi_step_window.test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
